# Smart Autoscaler Configuration
# Copy this file to .env and customize for your environment

# ============================================
# Required Settings
# ============================================

# Prometheus URL (required)
PROMETHEUS_URL=http://prometheus-server.monitoring:9090

# Watched deployments (comma-separated)
# Format: namespace/deployment/hpa-name
WATCHED_DEPLOYMENTS=default/my-app/my-app-hpa

# ============================================
# Scaling Settings
# ============================================

# Check interval in seconds (default: 60)
CHECK_INTERVAL=60

# Target node CPU utilization percentage (default: 30)
TARGET_NODE_UTILIZATION=30

# Enable dry-run mode - no actual scaling (default: false)
DRY_RUN=false

# Enable predictive scaling (default: true)
ENABLE_PREDICTIVE=true

# Enable auto-tuning (default: true)
ENABLE_AUTOTUNING=true

# Enable auto-discovery via annotations (default: true)
# When enabled, automatically discovers HPAs with annotation:
#   smart-autoscaler.io/enabled: "true"
ENABLE_AUTO_DISCOVERY=true

# ============================================
# Cost Settings (USD)
# ============================================

# Cost per vCPU per hour (default: 0.04)
# GKE e2-standard: ~$0.033/vCPU-hour
# GKE n2-standard: ~$0.049/vCPU-hour
COST_PER_VCPU_HOUR=0.04

# Cost per GB memory per hour (default: 0.005)
# Ratio: 1 vCPU : 8 GB memory (typical cloud pricing)
COST_PER_GB_MEMORY_HOUR=0.005

# ============================================
# Logging Settings
# ============================================

# Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
LOG_LEVEL=INFO

# Log format: json or text (default: json)
LOG_FORMAT=json

# ============================================
# Rate Limiting
# ============================================

# Prometheus queries per minute (default: 10)
PROMETHEUS_RATE_LIMIT=10

# Kubernetes API calls per minute (default: 20)
K8S_API_RATE_LIMIT=20

# ============================================
# Memory Management
# ============================================

# Memory warning threshold (default: 0.75)
MEMORY_WARNING_THRESHOLD=0.75

# Memory critical threshold (default: 0.9)
MEMORY_CRITICAL_THRESHOLD=0.9

# Memory check interval in seconds (default: 30)
MEMORY_CHECK_INTERVAL=30

# ============================================
# Deployment Configuration
# ============================================

# Startup Filter: Minutes to ignore newly started pods when calculating CPU metrics
# This prevents scaling decisions based on temporary CPU spikes during pod initialization
# (JVM warmup, cache loading, application startup, etc.)
#
# Recommended values:
# - Java/JVM apps: 3-5 minutes (slow startup, high CPU during initialization)
# - Node.js apps: 1-2 minutes (moderate startup time)
# - Go/Rust apps: 0-1 minutes (fast startup)
# - Default: 2 minutes
# - Range: 0-60 minutes

# Deployment 0 (example)
DEPLOYMENT_0_NAMESPACE=default
DEPLOYMENT_0_NAME=my-app
DEPLOYMENT_0_HPA_NAME=my-app-hpa
DEPLOYMENT_0_STARTUP_FILTER=2
DEPLOYMENT_0_PRIORITY=medium

# Deployment 1 (example - high priority API)
# DEPLOYMENT_1_NAMESPACE=production
# DEPLOYMENT_1_NAME=api-service
# DEPLOYMENT_1_HPA_NAME=api-service-hpa
# DEPLOYMENT_1_STARTUP_FILTER=2
# DEPLOYMENT_1_PRIORITY=high

# Deployment 2 (example - Java service with slow startup)
# DEPLOYMENT_2_NAMESPACE=production
# DEPLOYMENT_2_NAME=payment-service
# DEPLOYMENT_2_HPA_NAME=payment-service-hpa
# DEPLOYMENT_2_STARTUP_FILTER=5  # Higher for Java/JVM apps
# DEPLOYMENT_2_PRIORITY=critical

# Priority levels: critical, high, medium, low, best_effort
# - critical: Payment, Auth (55% HPA target, 2x faster scale up)
# - high: APIs, Gateways (60% HPA target, 1.5x faster scale up)
# - medium: Standard workloads (70% HPA target, normal speed) [DEFAULT]
# - low: Background jobs (80% HPA target, cost-optimized)
# - best_effort: Reports, Analytics (85% HPA target, maximum cost savings)

# ============================================
# GenAI Integration (optional)
# ============================================

# Enable GenAI features (default: false)
# Set to 'true' to enable AI-powered insights and explanations
ENABLE_GENAI=false

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini  # Options: gpt-4o-mini (fast/cheap), gpt-4o, gpt-3.5-turbo

# Google Gemini Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
# GEMINI_API_KEY=AIza...
# Model: gemini-1.5-flash (fast and efficient)

# Anthropic Claude Configuration
# Get your API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-...
# CLAUDE_MODEL=claude-3-haiku-20240307  # Options: claude-3-haiku (fast/cheap), claude-3-sonnet, claude-3-opus

# Note: Only one provider is needed. The system will auto-detect which API key is available.
# Priority order: OpenAI > Gemini > Claude > Mock (if no keys configured)

# ============================================
# Webhooks (optional)
# ============================================

# Slack webhook URL for notifications
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx/yyy/zzz

# Teams webhook URL for notifications
# TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/xxx
