# Smart Autoscaler Configuration
# Copy this file to .env and customize for your environment

# ============================================
# Required Settings
# ============================================

# Prometheus URL (required)
PROMETHEUS_URL=http://prometheus-server.monitoring:9090

# Watched deployments (comma-separated)
# Format: namespace/deployment/hpa-name
WATCHED_DEPLOYMENTS=default/my-app/my-app-hpa

# ============================================
# Scaling Settings
# ============================================

# Check interval in seconds (default: 60)
CHECK_INTERVAL=60

# Target node CPU utilization percentage (default: 30)
TARGET_NODE_UTILIZATION=30

# Enable dry-run mode - no actual scaling (default: false)
DRY_RUN=false

# Enable predictive scaling (default: true)
ENABLE_PREDICTIVE=true

# Enable auto-tuning (default: true)
ENABLE_AUTOTUNING=true

# Enable auto-discovery via annotations (default: true)
# When enabled, automatically discovers HPAs with annotation:
#   smart-autoscaler.io/enabled: "true"
ENABLE_AUTO_DISCOVERY=true

# ============================================
# Cost Settings (USD)
# ============================================

# Cost per vCPU per hour (default: 0.04)
# GKE e2-standard: ~$0.033/vCPU-hour
# GKE n2-standard: ~$0.049/vCPU-hour
COST_PER_VCPU_HOUR=0.04

# Cost per GB memory per hour (default: 0.005)
# Ratio: 1 vCPU : 8 GB memory (typical cloud pricing)
COST_PER_GB_MEMORY_HOUR=0.005

# ============================================
# Logging Settings
# ============================================

# Log level: DEBUG, INFO, WARNING, ERROR (default: INFO)
LOG_LEVEL=INFO

# Log format: json or text (default: json)
LOG_FORMAT=json

# ============================================
# Rate Limiting
# ============================================

# Prometheus queries per minute (default: 10)
PROMETHEUS_RATE_LIMIT=10

# Kubernetes API calls per minute (default: 20)
K8S_API_RATE_LIMIT=20

# ============================================
# Memory Management
# ============================================

# Memory warning threshold (default: 0.75)
MEMORY_WARNING_THRESHOLD=0.75

# Memory critical threshold (default: 0.9)
MEMORY_CRITICAL_THRESHOLD=0.9

# Memory check interval in seconds (default: 30)
MEMORY_CHECK_INTERVAL=30

# ============================================
# Database Settings
# ============================================

# Metrics retention in days (default: 30)
# Older metrics will be automatically deleted
METRICS_RETENTION_DAYS=30

# Predictions retention in days (default: 30)
PREDICTIONS_RETENTION_DAYS=30

# Anomalies retention in days (default: 90)
ANOMALIES_RETENTION_DAYS=90

# Database cleanup interval in hours (default: 6)
# How often to run automatic cleanup
DB_CLEANUP_INTERVAL_HOURS=6

# ============================================
# Disk Auto-Healing (Self-Healing)
# ============================================

# Disk usage warning threshold (default: 0.80 = 80%)
# Logs warning when disk usage exceeds this
DISK_WARNING_THRESHOLD=0.80

# Disk usage critical threshold (default: 0.90 = 90%)
# Triggers smart cleanup: downsample to 2-hourly averages for data >14 days
DISK_CRITICAL_THRESHOLD=0.90

# Disk usage emergency threshold (default: 0.95 = 95%)
# Triggers aggressive smart cleanup: preserve 168 weekly pattern slots + VACUUM
DISK_EMERGENCY_THRESHOLD=0.95

# ============================================
# Pre-Scale Settings (TRUE Pre-Scaling)
# ============================================

# Enable TRUE pre-scaling via HPA minReplicas (default: true)
ENABLE_PRESCALE=true

# Minimum prediction confidence to trigger pre-scale (default: 0.7)
PRESCALE_MIN_CONFIDENCE=0.7

# CPU threshold to trigger pre-scale (default: 75.0)
PRESCALE_THRESHOLD=75.0

# Auto-rollback timeout in minutes (default: 60)
PRESCALE_ROLLBACK_MINUTES=60

# Cooldown between pre-scale actions in minutes (default: 15)
PRESCALE_COOLDOWN_MINUTES=15

# ============================================
# Deployment Configuration
# ============================================

# Startup Filter: Minutes to ignore newly started pods when calculating CPU metrics
# This prevents scaling decisions based on temporary CPU spikes during pod initialization
# (JVM warmup, cache loading, application startup, etc.)
#
# Recommended values:
# - Java/JVM apps: 3-5 minutes (slow startup, high CPU during initialization)
# - Node.js apps: 1-2 minutes (moderate startup time)
# - Go/Rust apps: 0-1 minutes (fast startup)
# - Default: 2 minutes
# - Range: 0-60 minutes

# Deployment 0 (example)
DEPLOYMENT_0_NAMESPACE=default
DEPLOYMENT_0_NAME=my-app
DEPLOYMENT_0_HPA_NAME=my-app-hpa
DEPLOYMENT_0_STARTUP_FILTER=2
DEPLOYMENT_0_PRIORITY=medium

# Deployment 1 (example - high priority API)
# DEPLOYMENT_1_NAMESPACE=production
# DEPLOYMENT_1_NAME=api-service
# DEPLOYMENT_1_HPA_NAME=api-service-hpa
# DEPLOYMENT_1_STARTUP_FILTER=2
# DEPLOYMENT_1_PRIORITY=high

# Deployment 2 (example - Java service with slow startup)
# DEPLOYMENT_2_NAMESPACE=production
# DEPLOYMENT_2_NAME=payment-service
# DEPLOYMENT_2_HPA_NAME=payment-service-hpa
# DEPLOYMENT_2_STARTUP_FILTER=5  # Higher for Java/JVM apps
# DEPLOYMENT_2_PRIORITY=critical

# Priority levels: critical, high, medium, low, best_effort
# - critical: Payment, Auth (55% HPA target, 2x faster scale up)
# - high: APIs, Gateways (60% HPA target, 1.5x faster scale up)
# - medium: Standard workloads (70% HPA target, normal speed) [DEFAULT]
# - low: Background jobs (80% HPA target, cost-optimized)
# - best_effort: Reports, Analytics (85% HPA target, maximum cost savings)

# ============================================
# Autopilot Mode - Automatic Resource Tuning
# ============================================

# Enable autopilot mode (default: false)
# When enabled, automatically tunes CPU and memory REQUESTS based on P95 usage
# NOTE: Only tunes requests, NOT limits
ENABLE_AUTOPILOT=false

# Autopilot automation level (default: recommend)
# - disabled: No autopilot processing
# - observe: Only observe and log recommendations
# - recommend: Generate recommendations (visible in dashboard)
# - autopilot: Auto-apply safe changes with guardrails
AUTOPILOT_LEVEL=recommend

# Minimum days of observation data before auto-tuning (default: 7)
AUTOPILOT_MIN_OBSERVATION_DAYS=7

# Minimum confidence score to apply changes (default: 0.80)
AUTOPILOT_MIN_CONFIDENCE=0.80

# Maximum % change per iteration (default: 30)
# Prevents drastic changes - larger changes are split across multiple iterations
AUTOPILOT_MAX_CHANGE_PERCENT=30

# Hours to wait between changes for same deployment (default: 24)
AUTOPILOT_COOLDOWN_HOURS=24

# Minimum CPU request in millicores (default: 50)
AUTOPILOT_MIN_CPU_REQUEST=50

# Minimum memory request in MB (default: 64)
AUTOPILOT_MIN_MEMORY_REQUEST=64

# Buffer above P95 for CPU (default: 20%)
AUTOPILOT_CPU_BUFFER_PERCENT=20

# Buffer above P95 for memory (default: 25%)
AUTOPILOT_MEMORY_BUFFER_PERCENT=25

# ============================================
# Autopilot Auto-Rollback Settings
# ============================================

# Enable automatic rollback on health issues (default: true)
# When enabled, autopilot will automatically revert changes if:
# - Pod restarts increase beyond threshold
# - OOMKills are detected
# - Readiness drops significantly
AUTOPILOT_ENABLE_AUTO_ROLLBACK=true

# Minutes to monitor deployment health after changes (default: 10)
# During this window, health is checked every 30 seconds
AUTOPILOT_ROLLBACK_MONITOR_MINUTES=10

# Maximum pod restart increase before triggering rollback (default: 2)
# If restarts increase by more than this during monitoring, rollback is triggered
AUTOPILOT_MAX_RESTART_INCREASE=2

# Maximum OOMKill increase before triggering rollback (default: 1)
# Any OOMKill during monitoring window triggers immediate rollback
AUTOPILOT_MAX_OOM_INCREASE=1

# Maximum readiness drop percentage before rollback (default: 20)
# If ready replicas drop by more than this %, rollback is triggered
AUTOPILOT_MAX_READINESS_DROP_PERCENT=20

# ============================================
# Autopilot Learning Mode Settings
# ============================================

# Enable per-deployment learning mode (default: true)
# When enabled, autopilot observes each deployment for a learning period
# before making recommendations. Shows "Learning: Day X of Y" in dashboard.
AUTOPILOT_ENABLE_LEARNING_MODE=true

# Days required for learning phase (default: 7)
# Autopilot collects metrics during this period to establish baselines
AUTOPILOT_LEARNING_DAYS=7

# Auto-graduate after learning completes (default: true)
# When true, deployments automatically move from learning to active recommendations
# When false, manual graduation is required via API
AUTOPILOT_AUTO_GRADUATE=true

# ============================================
# GenAI Integration (optional)
# ============================================

# Enable GenAI features (default: false)
# Set to 'true' to enable AI-powered insights and explanations
ENABLE_GENAI=false

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini  # Options: gpt-4o-mini (fast/cheap), gpt-4o, gpt-3.5-turbo

# Google Gemini Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
# GEMINI_API_KEY=AIza...
# Model: gemini-1.5-flash (fast and efficient)

# Anthropic Claude Configuration
# Get your API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-...
# CLAUDE_MODEL=claude-3-haiku-20240307  # Options: claude-3-haiku (fast/cheap), claude-3-sonnet, claude-3-opus

# Note: Only one provider is needed. The system will auto-detect which API key is available.
# Priority order: OpenAI > Gemini > Claude > Mock (if no keys configured)

# ============================================
# Webhooks (optional)
# ============================================

# Slack webhook URL for notifications
# SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx/yyy/zzz

# Teams webhook URL for notifications
# TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/xxx
