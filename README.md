# Smart Kubernetes Autoscaler

ğŸš€ AI-Powered, Cost-Optimized, Node-Aware HPA Controller with Predictive Scaling

## âœ¨ Features

- ğŸ“Š **Historical Learning** - Learns patterns from 30 days of data
- ğŸ”® **Predictive Pre-Scaling** - Scales before spikes happen
- ğŸ’° **Cost Optimization** - Tracks and optimizes monthly costs
- ğŸš¨ **Anomaly Detection** - Detects 4 types of anomalies
- ğŸ¯ **Auto-Tuning** - Finds optimal HPA targets automatically
- ğŸ“¢ **Multi-Channel Alerts** - Slack, Teams, Discord, webhooks
- ğŸ“Š **Prometheus Metrics** - 20+ custom metrics
- ğŸ–¥ï¸ **Web Dashboard** - Beautiful real-time UI
- ğŸ¤– **ML Models** - Random Forest, ARIMA, ensemble predictions
- ğŸ”Œ **Integrations** - PagerDuty, Datadog, Grafana, Jira

## ğŸš€ Quick Start
```bash
# 1. Configure webhooks
kubectl edit configmap smart-autoscaler-config -n autoscaler-system

# 2. Deploy
kubectl apply -f k8s/

# 3. Access Dashboard
kubectl port-forward svc/smart-autoscaler 5000:5000 -n autoscaler-system
# Open http://localhost:5000

# 4. View Metrics
kubectl port-forward svc/smart-autoscaler 8000:8000 -n autoscaler-system
# Open http://localhost:8000/metrics
```

## ğŸ“¦ Installation

### Prerequisites
- Kubernetes 1.19+
- Prometheus with node-exporter
- kubectl configured
- 10GB persistent storage

### Deploy
```bash
# Build image
docker build -f Dockerfile.enhanced -t smart-autoscaler:latest .

# Push to your registry
docker tag smart-autoscaler:latest your-registry/smart-autoscaler:latest
docker push your-registry/smart-autoscaler:latest

# Update k8s/deployment.yaml with your image

# Deploy
kubectl apply -f k8s/
```

## âš™ï¸ Configuration

Edit `k8s/configmap.yaml`:
```yaml
PROMETHEUS_URL: "http://prometheus:9090"
CHECK_INTERVAL: "60"
TARGET_NODE_UTILIZATION: "70.0"
SLACK_WEBHOOK: "https://hooks.slack.com/..."
```

## ğŸ“Š Monitoring

- **Dashboard**: http://localhost:5000
- **Metrics**: http://localhost:8000/metrics
- **Logs**: `kubectl logs -f deployment/smart-autoscaler -n autoscaler-system`

## ğŸ¯ How It Works

1. Monitors node CPU utilization per deployment's node selector
2. Filters startup CPU spikes (first 2 minutes)
3. Uses 10m smoothed + 5m spike metrics (70/30 blend)
4. Predicts load based on historical patterns
5. Adjusts HPA targets dynamically
6. Detects anomalies and sends alerts
7. Tracks costs and suggests optimizations

## ğŸ“ Example HPA
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-service-hpa
spec:
  scaleTargetRef:
    kind: Deployment
    name: my-service
  minReplicas: 2
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Operator adjusts this dynamically
```

## ğŸ¤ Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md)

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE)

## ğŸ†˜ Support

- Issues: GitHub Issues
- Documentation: `/docs`
- Community: [Slack](https://join.slack.com/...)

---

**Built with â¤ï¸ for SRE teams**
